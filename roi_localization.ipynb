{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2511d0-f0ae-4354-9cdb-3f24d14ce759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from   ipywidgets import interactive, fixed\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from   pathlib import Path\n",
    "from   PIL import Image\n",
    "from   utils.utils import list_labelled_slices, calculate_IoU, difference, intersection, union\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca714f30-e4de-40e4-8dc6-75376cf596a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories and filenames\n",
    "results_dir = 'test_results_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de1365-db9d-4cc9-8856-4fd40fd4257c",
   "metadata": {},
   "source": [
    "### Slices with annotations (boundig box + class label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36219727-38a3-4e13-884d-06825401af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labelled_slices = list_labelled_slices()\n",
    "df_labelled_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5993b4-26e0-4a22-8dba-59a2434a9f97",
   "metadata": {},
   "source": [
    "### Predicted detections (bounding box + class label + classification score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f30bd59-947e-4ab9-b845-8847fd9d8e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all predictions\n",
    "results_dir = Path(results_dir)\n",
    "\n",
    "retina_net_detections = []\n",
    "study_ids             = []\n",
    "for i in results_dir.iterdir():\n",
    "    \n",
    "    if str(i.name).startswith('ae_') and i.is_dir():\n",
    "        for j in i.iterdir():\n",
    "            \n",
    "            study_id = j.stem\n",
    "            \n",
    "            if str(j.name).startswith('ae_') and str(j.name).endswith('.csv') and j.is_file():\n",
    "                retina_net_detections.append(str(j))\n",
    "                study_ids.append(str(study_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08f4d1-dae9-4311-9e28-917a909b2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter predictions for which there is a ground truth available\n",
    "detections_data = np.array([retina_net_detections, study_ids]).swapaxes(0,1)\n",
    "df_detections   = pd.DataFrame(detections_data, columns=['retina_net_detection', 'study_id'])\n",
    "\n",
    "detection_with_groundtruth = np.where(df_detections['study_id'].isin(df_labelled_slices['study_id']))[0].tolist()\n",
    "df_detections              = df_detections.iloc[detection_with_groundtruth]\n",
    "df_detections              = df_detections.sort_values(by='study_id')\n",
    "df_detections              = df_detections.reset_index(drop=True)\n",
    "df_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfdc73-a36f-4a51-b3fc-8f15423c7966",
   "metadata": {},
   "source": [
    "### Detections (TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5df2ae-b026-4c5c-a0ad-874eeab60519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections_from_ct_prediction(detections_scan):\n",
    "    \"\"\"\n",
    "    Load bounding box predictions for an entire CT scan from a csv file and return the slice scores.\n",
    "    \"\"\"\n",
    "    header = ['image_path','x1','y1','x2','y2','score']\n",
    "    \n",
    "    # Load prediction for a full CT scan\n",
    "    df_detections = pd.read_csv(detections_scan, names=header)\n",
    "    \n",
    "    # Extract bounding box coordinates and slice scores\n",
    "    x1     = df_detections['x1'].to_numpy()\n",
    "    y1     = df_detections['y1'].to_numpy()\n",
    "    x2     = df_detections['x2'].to_numpy()\n",
    "    y2     = df_detections['y2'].to_numpy()\n",
    "    scores = df_detections['score'].to_numpy()\n",
    "    \n",
    "    # Calculate bounding box parameters\n",
    "    #w    = x2 - x1\n",
    "    #h    = y2 - y1\n",
    "    bbox = [x1, y1, x2, y2]\n",
    "    bbox = np.asarray(bbox).swapaxes(0,1)\n",
    "    \n",
    "    return scores, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8feba-9f84-42f7-91ee-a82b7bc5eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_slices(scan, df_labelled_slices):\n",
    "    \n",
    "    # Load ground truth slice info\n",
    "    df_ct_scan  = df_labelled_slices.iloc[np.where(df_labelled_slices['scan'].isin([scan]))[0].tolist()]\n",
    "    true_slices = df_ct_scan['slice'].to_numpy(dtype=np.int64)\n",
    "    true_slices = np.sort(true_slices)\n",
    "    \n",
    "    return true_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75adaa-4d66-46d4-b9cf-175fb415eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_bboxes(scan, df_labelled_slices):\n",
    "    \n",
    "    # Load ground truth slice info\n",
    "    df_ct_scan  = df_labelled_slices.iloc[np.where(df_labelled_slices['scan'].isin([scan]))[0].tolist()]\n",
    "    annot_files = df_ct_scan['annot_file'].to_numpy()\n",
    "    \n",
    "    bboxes = []\n",
    "    for annot_file in annot_files:\n",
    "        with open(annot_file) as json_file:\n",
    "            annots = json.load(json_file)\n",
    "        \n",
    "        x1 = annots['x0']\n",
    "        y1 = annots['y0']\n",
    "        x2 = annots['x1']\n",
    "        y2 = annots['y2']\n",
    "    \n",
    "        bbox = [x1, y1, x2, y2]\n",
    "        bboxes.append(bbox)\n",
    "    \n",
    "    bboxes = np.asarray(bboxes)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83376b9-e345-465f-89ad-32803c817364",
   "metadata": {},
   "source": [
    "## ToDo\n",
    "\n",
    "Check IoU calculation. What if BBox = 0,0,1,1?\n",
    "\n",
    "Also, mean IoU is not the same as for evaluation script (0.74 vs. 0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f4bc0-a531-46e2-898a-14dded12cb9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over predictions\n",
    "print('Found {:d} predictions'.format(df_detections.shape[0]))\n",
    "\n",
    "scans            = []\n",
    "true_slices      = []\n",
    "detected_slices  = []\n",
    "IoUs             = []\n",
    "\n",
    "n_slices = 0\n",
    "n_annots = 0\n",
    "n_tp     = 0\n",
    "n_tn     = 0\n",
    "n_fp     = 0\n",
    "n_fn     = 0\n",
    "\n",
    "scores_in_annots = []\n",
    "scores_in_fps    = []\n",
    "scores_in_tns    = []\n",
    "IoUs_in_annots   = []\n",
    "\n",
    "for detection_ct in df_detections['retina_net_detection']:\n",
    "    \n",
    "    score_threshold = 0.05\n",
    "    IoU_thresholds  = 0.5\n",
    "    \n",
    "    scan                    = detection_ct.split('/ae_')[-1].split('.')[0]\n",
    "    true_slices_ct          = get_ground_truth_slices(scan, df_labelled_slices)\n",
    "    true_bbox_ct            = get_ground_truth_bboxes(scan, df_labelled_slices)\n",
    "    scores_ct, pred_bbox_ct = get_detections_from_ct_prediction(detection_ct)\n",
    "    \n",
    "    # Find slices with a detection\n",
    "    slices_ct          = np.arange(scores_ct.shape[0])\n",
    "    detected_slices_ct = np.empty([0], dtype=np.int64)\n",
    "    IoUs_detection_ct  = np.empty([0], dtype=np.float64)\n",
    "    IoUs_true_ct       = np.empty([0], dtype=np.float64)\n",
    "    for s, score, pred_bbox in zip(slices_ct, scores_ct, pred_bbox_ct):\n",
    "        \n",
    "        # Check if detection score is above threshold\n",
    "        if score > score_threshold:\n",
    "            detected_slices_ct = np.append(detected_slices_ct, s)\n",
    "            \n",
    "            # Calculate IoU\n",
    "            IoU = 0\n",
    "            \n",
    "            # Check if the detection is in an annotated slice\n",
    "            if s in true_slices_ct:\n",
    "                true_bbox = true_bbox_ct[np.where(true_slices_ct==s)][0]\n",
    "                IoU = calculate_IoU(pred_bbox, true_bbox)\n",
    "                \n",
    "            IoUs_detection_ct = np.append(IoUs_detection_ct, IoU)\n",
    "            \n",
    "        # Check if the slice is in an annotated slice\n",
    "        if s in true_slices_ct:\n",
    "            \n",
    "            # Calculate IoU\n",
    "            IoU = 0\n",
    "            \n",
    "            # Check if detection score is above threshold\n",
    "            if score > score_threshold:\n",
    "                true_bbox = true_bbox_ct[np.where(true_slices_ct==s)][0]\n",
    "                IoU = calculate_IoU(pred_bbox, true_bbox)\n",
    "                \n",
    "            IoUs_true_ct = np.append(IoUs_true_ct, IoU)\n",
    "            \n",
    "    scans.append(scan)\n",
    "    true_slices.append(true_slices_ct)\n",
    "    detected_slices.append(detected_slices_ct)\n",
    "    IoUs.append(IoUs_true_ct)\n",
    "    \n",
    "    #print('\\n************************************')\n",
    "    #print('Scan: {:s}'.format(scan))\n",
    "    #print('\\tTrue slices:     {}'.format(true_slices_ct))    \n",
    "    #print('\\tDetected slices: {}'.format(detected_slices_ct))\n",
    "    #print('\\tIoUs:            {}'.format(IoUs_true_ct))\n",
    "    \n",
    "    # Confusion matrix: Calculate TP, TN, FP, FN\n",
    "    n_slices_ct     = slices_ct.shape[0]\n",
    "    n_annots_ct     = true_slices_ct.shape[0]\n",
    "    n_detections_ct = detected_slices_ct.shape[0]\n",
    "    tp_ct =  intersection(true_slices_ct, detected_slices_ct)\n",
    "    tn_ct =  slices_ct[~np.isin(slices_ct, union(true_slices_ct, detected_slices_ct))]\n",
    "    fp_ct =  difference(detected_slices_ct, true_slices_ct)\n",
    "    fn_ct =  difference(true_slices_ct, detected_slices_ct)\n",
    "    \n",
    "    n_slices += n_slices_ct\n",
    "    n_annots += n_annots_ct\n",
    "    n_tp += tp_ct.shape[0]\n",
    "    n_tn += tn_ct.shape[0]\n",
    "    n_fp += fp_ct.shape[0]\n",
    "    n_fn += fn_ct.shape[0]\n",
    "    \n",
    "    #print('\\nConfusion matrix:')\n",
    "    #print('\\tn_slices     = {:d}'.format(n_slices_ct))\n",
    "    #print('\\tn_annots     = {:d}'.format(n_annots_ct))\n",
    "    #print('\\t# TP         = {:d}/{:d} ({:.2f} %)'.format(tp_ct.shape[0], n_annots_ct,             100*(float(tp_ct.shape[0])/float(n_annots_ct))))\n",
    "    #print('\\t# TN         = {:d}/{:d} ({:.2f} %)'.format(tn_ct.shape[0], n_slices_ct-n_annots_ct, 100*(float(tn_ct.shape[0])/float(n_slices_ct-n_annots_ct))))\n",
    "    #print('\\t# FP         = {:d}/{:d} ({:.2f} %)'.format(fp_ct.shape[0], n_slices_ct-n_annots_ct, 100*(float(fp_ct.shape[0])/float(n_slices_ct-n_annots_ct))))\n",
    "    #print('\\t# FN         = {:d}/{:d} ({:.2f} %)'.format(fn_ct.shape[0], n_annots_ct,             100*(float(fn_ct.shape[0])/float(n_annots_ct))))\n",
    "    \n",
    "    # Classification score\n",
    "    scores_in_annots_ct  = scores_ct[true_slices_ct]\n",
    "    scores_in_fp_ct      = scores_ct[fp_ct]\n",
    "    scores_in_tn_ct      = scores_ct[tn_ct]\n",
    "    \n",
    "    scores_in_annots.extend(scores_in_annots_ct)\n",
    "    scores_in_fps.extend(scores_in_fp_ct)\n",
    "    scores_in_tns.extend(scores_in_tn_ct)\n",
    "    \n",
    "    mean_score_in_annots = np.mean(scores_in_annots_ct)\n",
    "    #print('\\nScore statistics:')\n",
    "    #print('\\tMean score in n={:d} annotated slices = {:.1f}'.format(n_annots_ct, mean_score_in_annots))\n",
    "\n",
    "    # IoU: Average IoU in true slice\n",
    "    IoUs_in_annots.extend(IoUs_true_ct)\n",
    "    \n",
    "    #print('\\nAverage IoU in annotated slices:', np.mean(IoUs_true_ct))\n",
    "    \n",
    "print('Test set:')\n",
    "print('\\t# slices = {:d}'.format(n_slices))\n",
    "print('\\t# annots = {:d}'.format(n_annots))\n",
    "print('\\t# TP     = {:d}/{:d} ({:.1f} %)'.format(n_tp, n_annots,          100*(float(n_tp)/float(n_annots))))\n",
    "print('\\t# TN     = {:d}/{:d} ({:.1f} %)'.format(n_tn, n_slices-n_annots, 100*(float(n_tn)/float(n_slices-n_annots))))\n",
    "print('\\t# FP     = {:d}/{:d} ({:.1f} %)'.format(n_fp, n_slices-n_annots, 100*(float(n_fp)/float(n_slices-n_annots))))\n",
    "print('\\t# FN     = {:d}/{:d} ({:.1f} %)'.format(n_fn, n_annots,          100*(float(n_fn)/float(n_annots))))\n",
    "print('\\n\\tMean score in annots = {:.2f} [{:.2f},{:.2f}]'.format(np.median(scores_in_annots), np.quantile(scores_in_annots, q=0.25), np.quantile(scores_in_annots, q=0.75)))\n",
    "print('\\tMean score in fps    = {:.2f} [{:.2f},{:.2f}]'.format(np.median(scores_in_fps),    np.quantile(scores_in_fps, q=0.25),    np.quantile(scores_in_fps, q=0.75)))\n",
    "print('\\tMean score in tns    = {:.2f} [{:.2f},{:.2f}]'.format(np.median(scores_in_tns),    np.quantile(scores_in_tns, q=0.25),    np.quantile(scores_in_tns, q=0.75)))\n",
    "print('\\tMean IoU in annots   = {:.2f} [{:.2f},{:.2f}]'.format(np.median(IoUs_in_annots), np.quantile(IoUs_in_annots, q=0.25), np.quantile(IoUs_in_annots, q=0.75)))\n",
    "print('\\tMean IoU in detect   = {:.2f} [{:.2f},{:.2f}]'.format(np.median(IoUs_detection_ct), np.quantile(IoUs_detection_ct, q=0.25), np.quantile(IoUs_detection_ct, q=0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd5c69-099b-4200-867f-50d994aff149",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(IoUs_detection_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda89ea-653b-49ff-82e5-093133fa4c4b",
   "metadata": {},
   "source": [
    "### Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266daa52-b391-473a-bb7e-889950e43694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fc513-6f9c-446a-8be0-820046dcfd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over predictions\n",
    "print('Found {:d} predictions'.format(df_detections.shape[0]))\n",
    "\n",
    "scans            = []\n",
    "scores           = []\n",
    "bbox             = []\n",
    "localized_slices = []\n",
    "true_slices      = []\n",
    "hits             = []\n",
    "xy_dists_tp      = []\n",
    "xy_dists_fp      = []\n",
    "\n",
    "tp_det = 0\n",
    "fp_det = 0\n",
    "fn_det = 0\n",
    "\n",
    "for detection_ct in df_detections['retina_net_detection']:\n",
    "    \n",
    "    score_threshold = 0.05\n",
    "    \n",
    "    scan               = detection_ct.split('/ae_')[-1].split('.')[0]\n",
    "    true_slices_ct     = get_ground_truth_slices(scan, df_labelled_slices)\n",
    "    true_bbox_ct       = get_ground_truth_bboxes(scan, df_labelled_slices)\n",
    "    scores_ct, bbox_ct = get_detections_from_ct_prediction(detection_ct)\n",
    "\n",
    "    # Check if there is a detection with a classification score above the threshold\n",
    "    if np.amax(scores_ct) > score_threshold:\n",
    "        # Pick the slice(s) with the highest classification score. Typically, this will be a single slice\n",
    "        loc_slice = np.where(scores_ct==np.amax(scores_ct))[0]\n",
    "        \n",
    "        if loc_slice.shape[0] > 1:\n",
    "            print(\"WARNING: Localized more than 1 slice!\")\n",
    "            break\n",
    "        \n",
    "        # Check if one or more of the picked slices is in the list of true slices\n",
    "        slice_overlap = set(loc_slice).intersection(set(true_slices_ct))\n",
    "        slice_overlap = list(slice_overlap)\n",
    "\n",
    "        # Store results\n",
    "        if len(slice_overlap) > 0:\n",
    "            hits.append(1)\n",
    "            tp_det +=1\n",
    "            \n",
    "            # xy-plane distance\n",
    "            true_bbox = true_bbox_ct[np.where(true_slices_ct==loc_slice)][0]\n",
    "            loc_bbox  = bbox_ct[loc_slice][0]\n",
    "            \n",
    "            true_x = true_bbox[2] - true_bbox[0]\n",
    "            true_y = true_bbox[3] - true_bbox[1]\n",
    "            \n",
    "            loc_x  = loc_bbox[2] - loc_bbox[0]\n",
    "            loc_y  = loc_bbox[3] - loc_bbox[1]\n",
    "            \n",
    "            loc_xy_distance = np.sqrt( (loc_x-true_x)**2 + (loc_y-true_y)**2 )\n",
    "            xy_dists_tp.append(loc_xy_distance)\n",
    "            \n",
    "        else:\n",
    "            hits.append(0)\n",
    "            fp_det += 1\n",
    "            \n",
    "            # Find nearest true slice\n",
    "            nearest_true_slice = find_nearest(true_slices_ct, loc_slice)\n",
    "            \n",
    "            # xy-plane distance\n",
    "            true_bbox = true_bbox_ct[np.where(true_slices_ct==nearest_true_slice)][0]\n",
    "            loc_bbox  = bbox_ct[loc_slice][0]\n",
    "            \n",
    "            true_x = true_bbox[2] - true_bbox[0]\n",
    "            true_y = true_bbox[3] - true_bbox[1]\n",
    "            \n",
    "            loc_x  = loc_bbox[2] - loc_bbox[0]\n",
    "            loc_y  = loc_bbox[3] - loc_bbox[1]\n",
    "            \n",
    "            loc_xy_distance = np.sqrt( (loc_x-true_x)**2 + (loc_y-true_y)**2 )\n",
    "            xy_dists_fp.append(loc_xy_distance)\n",
    "    \n",
    "    else:\n",
    "        loc_slice = np.empty(shape=(0))\n",
    "        hits.append(0)\n",
    "        fn_det += 1\n",
    "        \n",
    "    print('\\nScan: {:s}'.format(scan))\n",
    "    print('\\tTrue slices:      {}'.format(true_slices_ct))\n",
    "    print('\\tLocalized slices: {}'.format(loc_slice))\n",
    "        \n",
    "    scans.append(scan)\n",
    "    scores.append(scores_ct)\n",
    "    bbox.append(np.asarray(bbox_ct))\n",
    "    localized_slices.append(loc_slice)\n",
    "    true_slices.append(true_slices_ct)\n",
    "    \n",
    "hits = np.asarray(hits)\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print('\\t#TP = {:d}'.format(tp_det))\n",
    "print('\\t#FP = {:d}'.format(fp_det))\n",
    "print('\\t#FN = {:d}'.format(fn_det))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359b4ab-6625-494f-8629-4ea6c6eba962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b100c8-3c36-4450-8e29-663d06b277ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average localization distance in xy-plane for TPs: {:.1f} +/- {:.1f} pxl (n={:d})'.format(np.mean(xy_dists_tp), np.std(xy_dists_tp), len(xy_dists_tp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb064075-049e-412d-a6a5-1e0cc32bd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average localization distance in xy-plane for FPs: {:.1f} +/- {:.1f} pxl (n={:d})'.format(np.mean(xy_dists_fp), np.std(xy_dists_fp), len(xy_dists_fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795dc69e-8ec4-44c8-b971-dff3a86d2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(scans, scores, bbox, predicted_slices, true_slices, scan_id, slice_id):\n",
    "    \n",
    "    scan    = scans[scan_id]\n",
    "    patient = scan.split('_')[0]\n",
    "    \n",
    "    image_path = '/data/public/age_estimation/jpg/ae_'+patient+'/ae_'+scan+'/ae_'+scan+'_s_'+str(slice_id)+'.jpg'\n",
    "    \n",
    "    print('Scan: {:s}'.format(scans[scan_id]))    \n",
    "    print('Image path: {:s}'.format(image_path))\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = np.asarray(image)\n",
    "    \n",
    "    x1, y1, w, h = bbox[scan_id][:,slice_id]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax[0].plot(scores[scan_id], c='r', label='algorithm score')\n",
    "    if predicted_slices[scan_id].size != 0:\n",
    "        ax[0].plot(predicted_slices[scan_id], np.ones_like(predicted_slices[scan_id]), c='k')\n",
    "        ax[0].axvline(x=np.mean(predicted_slices[scan_id]), ls='--', lw=1.5, c='k')\n",
    "    ax[0].axvline(x=np.mean(true_slices[scan_id]), ls='-.', lw=1.5, c='g')\n",
    "    ax[0].axvline(x=slice_id, ls='--', lw=1.5, c='b', label='current slice')\n",
    "    ax[0].set_ylim(0,1)\n",
    "    ax[0].tick_params(labelsize=14)\n",
    "    ax[0].set_xlabel('slice', fontsize=16)\n",
    "    ax[0].set_ylabel('score', fontsize=16)\n",
    "    ax[0].legend(fontsize=14)\n",
    "    \n",
    "    ax[1].imshow(image[100:-100,100:-100])\n",
    "    patch = plt.Rectangle([x1-100, y1-100], w, h, fill=False, edgecolor='r', linewidth=3)\n",
    "    ax[1].add_patch(patch)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072c99b-fde9-47ec-a831-9941c22a7697",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(plotter,\n",
    "            scans            = fixed(scans),\n",
    "            scores           = fixed(scores),\n",
    "            bbox             = fixed(bbox),\n",
    "            predicted_slices = fixed(localized_slices),\n",
    "            true_slices      = fixed(true_slices),\n",
    "            scan_id          = (0,len(scans)-1),\n",
    "            slice_id         = (0,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8fd78-4456-4974-a7b4-373b38851414",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot = hits.shape[0]\n",
    "n_0   = np.where(hits==0)[0].shape[0]\n",
    "n_1   = np.where(hits==1)[0].shape[0]\n",
    "accuracy = (float(n_tot-n_0) / float(n_tot)) * 100\n",
    "print('Accuracy = {:d}/{:d} ({:.2f} %)'.format(n_1, n_tot, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc676a4-39f5-498f-bdf2-7023d1f0e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(hits, bins=[0,1,2], color='cornflowerblue')\n",
    "plt.xticks([0.5,1.5], [0,1])\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.xlabel('result', fontsize=16)\n",
    "plt.ylabel('count', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4014b4c-eac8-4a86-b228-39b3e1719013",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Misses:')\n",
    "for miss in np.where(hits==0)[0]:\n",
    "    print('\\tPredicted slice:', localized_slices[miss], 'Annotated slices:', true_slices[miss])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
