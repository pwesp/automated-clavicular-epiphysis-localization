{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd895269-e3d4-4fb5-9dd9-05b72c3e6992",
   "metadata": {},
   "source": [
    "## SOI Localization Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2511d0-f0ae-4354-9cdb-3f24d14ce759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from   ipywidgets import interactive, fixed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from   pathlib import Path\n",
    "from   PIL import Image\n",
    "from   utils.evaluation import get_annotated_slices, get_detections, get_ground_truth_bboxes, get_ground_truth_slices, get_scores_and_bboxes\n",
    "from   utils.metrics import IoU\n",
    "from   utils.sets import difference, intersection, union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60e58d-2e68-4125-ade5-31a5b7a3a00c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca714f30-e4de-40e4-8dc6-75376cf596a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = 'my_annotations.csv'\n",
    "results_dir     = 'results'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de1365-db9d-4cc9-8856-4fd40fd4257c",
   "metadata": {},
   "source": [
    "### Grount truth (annotations)\n",
    "\n",
    "CT slices which have been annotated with a bounding box and a class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede8ee05-34ab-4275-a34e-139310117d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>class_name</th>\n",
       "      <th>ct_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>data/ct_scan_0/ae_0_0_3_s_258.jpg</td>\n",
       "      <td>216.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>sternum</td>\n",
       "      <td>ct_scan_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>data/ct_scan_0/ae_0_0_3_s_259.jpg</td>\n",
       "      <td>214.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>sternum</td>\n",
       "      <td>ct_scan_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>data/ct_scan_1/ae_1_1_3_s_238.jpg</td>\n",
       "      <td>216.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>sternum</td>\n",
       "      <td>ct_scan_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>data/ct_scan_2/ae_10_0_9_s_70.jpg</td>\n",
       "      <td>212.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>sternum</td>\n",
       "      <td>ct_scan_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_path     x1     y1     x2     y2 class_name  \\\n",
       "177  data/ct_scan_0/ae_0_0_3_s_258.jpg  216.0  230.0  276.0  259.0    sternum   \n",
       "178  data/ct_scan_0/ae_0_0_3_s_259.jpg  214.0  231.0  277.0  259.0    sternum   \n",
       "483  data/ct_scan_1/ae_1_1_3_s_238.jpg  216.0  241.0  289.0  267.0    sternum   \n",
       "692  data/ct_scan_2/ae_10_0_9_s_70.jpg  212.0  194.0  306.0  233.0    sternum   \n",
       "\n",
       "         ct_id  \n",
       "177  ct_scan_0  \n",
       "178  ct_scan_0  \n",
       "483  ct_scan_1  \n",
       "692  ct_scan_2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotated_slices = get_annotated_slices(annotation_file)\n",
    "df_annotated_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5993b4-26e0-4a22-8dba-59a2434a9f97",
   "metadata": {},
   "source": [
    "### Predictions (RetinaNet detections)\n",
    "\n",
    "CT slices for which the RetinaNet has predicted a bounding box and class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba6c5a1-059d-4bd1-91a8-f3ee7363b03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retina_net_detections</th>\n",
       "      <th>ct_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>results/ct_scan_0/ct_scan_0_predictions.csv</td>\n",
       "      <td>ct_scan_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>results/ct_scan_1/ct_scan_1_predictions.csv</td>\n",
       "      <td>ct_scan_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>results/ct_scan_2/ct_scan_2_predictions.csv</td>\n",
       "      <td>ct_scan_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         retina_net_detections      ct_id\n",
       "0  results/ct_scan_0/ct_scan_0_predictions.csv  ct_scan_0\n",
       "1  results/ct_scan_1/ct_scan_1_predictions.csv  ct_scan_1\n",
       "2  results/ct_scan_2/ct_scan_2_predictions.csv  ct_scan_2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detections = get_detections(results_dir, df_annotated_slices)\n",
    "df_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfdc73-a36f-4a51-b3fc-8f15423c7966",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Obejct Detection\n",
    "\n",
    "#### ToDo\n",
    "\n",
    "Check IoU calculation. What if BBox = 0,0,1,1?\n",
    "\n",
    "Also, mean IoU is not the same as for evaluation script (0.74 vs. 0.88)\n",
    "\n",
    "Check IoU calculation. What if BBox = 0,0,1,1?\n",
    "\n",
    "Also, mean IoU is not the same as for evaluation script (0.74 vs. 0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf1fa3d-962b-4b46-95ed-5539373c41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_object_detection(df_detections, df_annotated_slices):\n",
    "    # Loop over predictions\n",
    "    print('Found predictions for n={:d} CT scans'.format(df_detections.shape[0]))\n",
    "\n",
    "    ct_scans         = []\n",
    "    true_slices      = []\n",
    "    detected_slices  = []\n",
    "    IoUs             = []\n",
    "\n",
    "    n_slices = 0\n",
    "    n_annots = 0\n",
    "    n_tp     = 0\n",
    "    n_tn     = 0\n",
    "    n_fp     = 0\n",
    "    n_fn     = 0\n",
    "\n",
    "    scores_in_annots = []\n",
    "    scores_in_fps    = []\n",
    "    scores_in_tns    = []\n",
    "    IoUs_in_annots   = []\n",
    "\n",
    "    for i, detection_ct in enumerate(df_detections['retina_net_detections']):\n",
    "\n",
    "        score_threshold = 0.05\n",
    "        IoU_thresholds  = 0.5\n",
    "\n",
    "        scan                    = detection_ct.split('/')[1]\n",
    "        true_slices_ct          = get_ground_truth_slices(scan, df_annotated_slices)\n",
    "        true_bbox_ct            = get_ground_truth_bboxes(scan, df_annotated_slices)\n",
    "        scores_ct, pred_bbox_ct = get_scores_and_bboxes(detection_ct)\n",
    "\n",
    "        # Find slices with a detection\n",
    "        slices_ct          = np.arange(scores_ct.shape[0])\n",
    "        detected_slices_ct = np.empty([0], dtype=np.int64)\n",
    "        IoUs_detection_ct  = np.empty([0], dtype=np.float64)\n",
    "        IoUs_true_ct       = np.empty([0], dtype=np.float64)\n",
    "        for s, score, pred_bbox in zip(slices_ct, scores_ct, pred_bbox_ct):\n",
    "\n",
    "            # Check if detection score is above threshold\n",
    "            if score > score_threshold:\n",
    "                detected_slices_ct = np.append(detected_slices_ct, s)\n",
    "\n",
    "                # Calculate IoU\n",
    "                IoU_slice = 0\n",
    "\n",
    "                # Check if the detection is in an annotated slice\n",
    "                if s in true_slices_ct:\n",
    "                    true_bbox = true_bbox_ct[np.where(true_slices_ct==s)][0]\n",
    "                    IoU_slice = IoU(pred_bbox, true_bbox)\n",
    "\n",
    "                IoUs_detection_ct = np.append(IoUs_detection_ct, IoU)\n",
    "\n",
    "            # Check if the slice is in an annotated slice\n",
    "            if s in true_slices_ct:\n",
    "\n",
    "                # Calculate IoU\n",
    "                IoU_slice = 0\n",
    "\n",
    "                # Check if detection score is above threshold\n",
    "                if score > score_threshold:\n",
    "                    true_bbox = true_bbox_ct[np.where(true_slices_ct==s)][0]\n",
    "                    IoU_slice = IoU(pred_bbox, true_bbox)\n",
    "\n",
    "                IoUs_true_ct = np.append(IoUs_true_ct, IoU_slice)\n",
    "\n",
    "        ct_scans.append(scan)\n",
    "        true_slices.append(true_slices_ct)\n",
    "        detected_slices.append(detected_slices_ct)\n",
    "        IoUs.append(IoUs_true_ct)\n",
    "\n",
    "        print('\\n************************************')\n",
    "        print('Scan: {:s}'.format(scan))\n",
    "        print('\\tTrue slices:     {}'.format(true_slices_ct))    \n",
    "        print('\\tDetected slices: {}'.format(detected_slices_ct))\n",
    "        print('\\tIoUs:            {}'.format(IoUs_true_ct))\n",
    "\n",
    "        # Confusion matrix: Calculate TP, TN, FP, FN\n",
    "        n_slices_ct     = slices_ct.shape[0]\n",
    "        n_annots_ct     = true_slices_ct.shape[0]\n",
    "        n_detections_ct = detected_slices_ct.shape[0]\n",
    "        tp_ct =  intersection(true_slices_ct, detected_slices_ct)\n",
    "        tn_ct =  slices_ct[~np.isin(slices_ct, union(true_slices_ct, detected_slices_ct))]\n",
    "        fp_ct =  difference(detected_slices_ct, true_slices_ct)\n",
    "        fn_ct =  difference(true_slices_ct, detected_slices_ct)\n",
    "\n",
    "        n_slices += n_slices_ct\n",
    "        n_annots += n_annots_ct\n",
    "        n_tp += tp_ct.shape[0]\n",
    "        n_tn += tn_ct.shape[0]\n",
    "        n_fp += fp_ct.shape[0]\n",
    "        n_fn += fn_ct.shape[0]\n",
    "\n",
    "        print('\\nConfusion matrix:')\n",
    "        print('\\tn_slices     = {:d}'.format(n_slices_ct))\n",
    "        print('\\tn_annots     = {:d}'.format(n_annots_ct))\n",
    "        print('\\t# TP         = {:d}/{:d} ({:.2f} %)'.format(tp_ct.shape[0], n_annots_ct,             100*(float(tp_ct.shape[0])/float(n_annots_ct))))\n",
    "        print('\\t# TN         = {:d}/{:d} ({:.2f} %)'.format(tn_ct.shape[0], n_slices_ct-n_annots_ct, 100*(float(tn_ct.shape[0])/float(n_slices_ct-n_annots_ct))))\n",
    "        print('\\t# FP         = {:d}/{:d} ({:.2f} %)'.format(fp_ct.shape[0], n_slices_ct-n_annots_ct, 100*(float(fp_ct.shape[0])/float(n_slices_ct-n_annots_ct))))\n",
    "        print('\\t# FN         = {:d}/{:d} ({:.2f} %)'.format(fn_ct.shape[0], n_annots_ct,             100*(float(fn_ct.shape[0])/float(n_annots_ct))))\n",
    "\n",
    "        # Classification score\n",
    "        scores_in_annots_ct  = scores_ct[true_slices_ct]\n",
    "        scores_in_fp_ct      = scores_ct[fp_ct]\n",
    "        scores_in_tn_ct      = scores_ct[tn_ct]\n",
    "\n",
    "        scores_in_annots.extend(scores_in_annots_ct)\n",
    "        scores_in_fps.extend(scores_in_fp_ct)\n",
    "        scores_in_tns.extend(scores_in_tn_ct)\n",
    "\n",
    "        mean_score_in_annots = np.mean(scores_in_annots_ct)\n",
    "        #print('\\nScore statistics:')\n",
    "        #print('\\tMean score in n={:d} annotated slices = {:.1f}'.format(n_annots_ct, mean_score_in_annots))\n",
    "\n",
    "        # IoU: Average IoU in true slice\n",
    "        IoUs_in_annots.extend(IoUs_true_ct)\n",
    "\n",
    "        #print('\\nAverage IoU in annotated slices:', np.mean(IoUs_true_ct))\n",
    "\n",
    "    print('\\nTest set:')\n",
    "    print('\\t# slices = {:d}'.format(n_slices))\n",
    "    print('\\t# annots = {:d}'.format(n_annots))\n",
    "    print('\\t# TP     = {:d}/{:d} ({:.1f} %)'.format(n_tp, n_annots,          100*(float(n_tp)/float(n_annots))))\n",
    "    print('\\t# TN     = {:d}/{:d} ({:.1f} %)'.format(n_tn, n_slices-n_annots, 100*(float(n_tn)/float(n_slices-n_annots))))\n",
    "    print('\\t# FP     = {:d}/{:d} ({:.1f} %)'.format(n_fp, n_slices-n_annots, 100*(float(n_fp)/float(n_slices-n_annots))))\n",
    "    print('\\t# FN     = {:d}/{:d} ({:.1f} %)'.format(n_fn, n_annots,          100*(float(n_fn)/float(n_annots))))\n",
    "    print('\\n\\tMean score in annots = {:.2f} [{:.2f},{:.2f}]'.format(np.median(scores_in_annots), np.quantile(scores_in_annots, q=0.25), np.quantile(scores_in_annots, q=0.75)))\n",
    "    #print('\\tMean score in fps    = {:.2f} [{:.2f},{:.2f}]'.format(np.median(scores_in_fps),    np.quantile(scores_in_fps, q=0.25),    np.quantile(scores_in_fps, q=0.75)))\n",
    "    #print('\\tMean score in tns    = {:.2f} [{:.2f},{:.2f}]'.format(np.median(scores_in_tns),    np.quantile(scores_in_tns, q=0.25),    np.quantile(scores_in_tns, q=0.75)))\n",
    "    #print('\\tMean IoU in annots   = {:.2f} [{:.2f},{:.2f}]'.format(np.median(IoUs_in_annots), np.quantile(IoUs_in_annots, q=0.25), np.quantile(IoUs_in_annots, q=0.75)))\n",
    "    #print('\\tMean IoU in detect   = {:.2f} [{:.2f},{:.2f}]'.format(np.median(IoUs_detection_ct), np.quantile(IoUs_detection_ct, q=0.25), np.quantile(IoUs_detection_ct, q=0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73374337-40ec-4ad2-a853-d1a5e0667fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found predictions for n=3 CT scans\n",
      "\n",
      "************************************\n",
      "Scan: ct_scan_0\n",
      "\tTrue slices:     [258 259]\n",
      "\tDetected slices: [258 259]\n",
      "\tIoUs:            [0.73191611 0.865768  ]\n",
      "\n",
      "Confusion matrix:\n",
      "\tn_slices     = 328\n",
      "\tn_annots     = 2\n",
      "\t# TP         = 2/2 (100.00 %)\n",
      "\t# TN         = 326/326 (100.00 %)\n",
      "\t# FP         = 0/326 (0.00 %)\n",
      "\t# FN         = 0/2 (0.00 %)\n",
      "\n",
      "************************************\n",
      "Scan: ct_scan_1\n",
      "\tTrue slices:     [238]\n",
      "\tDetected slices: [238]\n",
      "\tIoUs:            [0.79716465]\n",
      "\n",
      "Confusion matrix:\n",
      "\tn_slices     = 296\n",
      "\tn_annots     = 1\n",
      "\t# TP         = 1/1 (100.00 %)\n",
      "\t# TN         = 295/295 (100.00 %)\n",
      "\t# FP         = 0/295 (0.00 %)\n",
      "\t# FN         = 0/1 (0.00 %)\n",
      "\n",
      "************************************\n",
      "Scan: ct_scan_2\n",
      "\tTrue slices:     [70]\n",
      "\tDetected slices: [70]\n",
      "\tIoUs:            [0.97592318]\n",
      "\n",
      "Confusion matrix:\n",
      "\tn_slices     = 93\n",
      "\tn_annots     = 1\n",
      "\t# TP         = 1/1 (100.00 %)\n",
      "\t# TN         = 92/92 (100.00 %)\n",
      "\t# FP         = 0/92 (0.00 %)\n",
      "\t# FN         = 0/1 (0.00 %)\n",
      "\n",
      "Test set:\n",
      "\t# slices = 717\n",
      "\t# annots = 4\n",
      "\t# TP     = 4/4 (100.0 %)\n",
      "\t# TN     = 713/713 (100.0 %)\n",
      "\t# FP     = 0/713 (0.0 %)\n",
      "\t# FN     = 0/4 (0.0 %)\n",
      "\n",
      "\tMean score in annots = 1.00 [1.00,1.00]\n"
     ]
    }
   ],
   "source": [
    "evaluate_object_detection(df_detections, df_annotated_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda89ea-653b-49ff-82e5-093133fa4c4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Structure-Of-Interest (SOI) Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266daa52-b391-473a-bb7e-889950e43694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fc513-6f9c-446a-8be0-820046dcfd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over predictions\n",
    "print('Found predictions for n={:d} CT scans'.format(df_detections.shape[0]))\n",
    "\n",
    "scans            = []\n",
    "scores           = []\n",
    "bbox             = []\n",
    "localized_slices = []\n",
    "true_slices      = []\n",
    "hits             = []\n",
    "xy_dists_tp      = []\n",
    "xy_dists_fp      = []\n",
    "\n",
    "tp_det = 0\n",
    "fp_det = 0\n",
    "fn_det = 0\n",
    "\n",
    "for detection_ct in df_detections['retina_net_detections']:\n",
    "    \n",
    "    score_threshold = 0.05\n",
    "    \n",
    "    scan               = detection_ct.split('/')[1]\n",
    "    true_slices_ct     = get_ground_truth_slices(scan, df_annotated_slices)\n",
    "    true_bbox_ct       = get_ground_truth_bboxes(scan, df_annotated_slices)\n",
    "    scores_ct, bbox_ct = get_detections(detection_ct)\n",
    "\n",
    "    # Check if there is a detection with a classification score above the threshold\n",
    "    if np.amax(scores_ct) > score_threshold:\n",
    "        # Pick the slice(s) with the highest classification score. Typically, this will be a single slice\n",
    "        loc_slice = np.where(scores_ct==np.amax(scores_ct))[0]\n",
    "        \n",
    "        if loc_slice.shape[0] > 1:\n",
    "            print(\"WARNING: Localized more than 1 slice!\")\n",
    "            break\n",
    "        \n",
    "        # Check if one or more of the picked slices is in the list of true slices\n",
    "        slice_overlap = set(loc_slice).intersection(set(true_slices_ct))\n",
    "        slice_overlap = list(slice_overlap)\n",
    "\n",
    "        # Store results\n",
    "        if len(slice_overlap) > 0:\n",
    "            hits.append(1)\n",
    "            tp_det +=1\n",
    "            \n",
    "            # xy-plane distance\n",
    "            true_bbox = true_bbox_ct[np.where(true_slices_ct==loc_slice)][0]\n",
    "            loc_bbox  = bbox_ct[loc_slice][0]\n",
    "            \n",
    "            true_x = true_bbox[2] - true_bbox[0]\n",
    "            true_y = true_bbox[3] - true_bbox[1]\n",
    "            \n",
    "            loc_x  = loc_bbox[2] - loc_bbox[0]\n",
    "            loc_y  = loc_bbox[3] - loc_bbox[1]\n",
    "            \n",
    "            loc_xy_distance = np.sqrt( (loc_x-true_x)**2 + (loc_y-true_y)**2 )\n",
    "            xy_dists_tp.append(loc_xy_distance)\n",
    "            \n",
    "        else:\n",
    "            hits.append(0)\n",
    "            fp_det += 1\n",
    "            \n",
    "            # Find nearest true slice\n",
    "            nearest_true_slice = find_nearest(true_slices_ct, loc_slice)\n",
    "            \n",
    "            # xy-plane distance\n",
    "            true_bbox = true_bbox_ct[np.where(true_slices_ct==nearest_true_slice)][0]\n",
    "            loc_bbox  = bbox_ct[loc_slice][0]\n",
    "            \n",
    "            true_x = true_bbox[2] - true_bbox[0]\n",
    "            true_y = true_bbox[3] - true_bbox[1]\n",
    "            \n",
    "            loc_x  = loc_bbox[2] - loc_bbox[0]\n",
    "            loc_y  = loc_bbox[3] - loc_bbox[1]\n",
    "            \n",
    "            loc_xy_distance = np.sqrt( (loc_x-true_x)**2 + (loc_y-true_y)**2 )\n",
    "            xy_dists_fp.append(loc_xy_distance)\n",
    "    \n",
    "    else:\n",
    "        loc_slice = np.empty(shape=(0))\n",
    "        hits.append(0)\n",
    "        fn_det += 1\n",
    "    \n",
    "    print('\\n************************************')    \n",
    "    print('Scan: {:s}'.format(scan))\n",
    "    print('\\tTrue slices:      {}'.format(true_slices_ct))\n",
    "    print('\\tLocalized slices: {}'.format(loc_slice))\n",
    "        \n",
    "    scans.append(scan)\n",
    "    scores.append(scores_ct)\n",
    "    bbox.append(np.asarray(bbox_ct))\n",
    "    localized_slices.append(loc_slice)\n",
    "    true_slices.append(true_slices_ct)\n",
    "    \n",
    "hits = np.asarray(hits)\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print('\\t#TP = {:d}'.format(tp_det))\n",
    "print('\\t#FP = {:d}'.format(fp_det))\n",
    "print('\\t#FN = {:d}'.format(fn_det))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359b4ab-6625-494f-8629-4ea6c6eba962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4014b4c-eac8-4a86-b228-39b3e1719013",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Misses:')\n",
    "for miss in np.where(hits==0)[0]:\n",
    "    print('\\tPredicted slice:', localized_slices[miss], 'Annotated slices:', true_slices[miss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b100c8-3c36-4450-8e29-663d06b277ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average localization distance in xy-plane for TPs: {:.1f} +/- {:.1f} pxl (n={:d})'.format(np.mean(xy_dists_tp), np.std(xy_dists_tp), len(xy_dists_tp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb064075-049e-412d-a6a5-1e0cc32bd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average localization distance in xy-plane for FPs: {:.1f} +/- {:.1f} pxl (n={:d})'.format(np.mean(xy_dists_fp), np.std(xy_dists_fp), len(xy_dists_fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8fd78-4456-4974-a7b4-373b38851414",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot = hits.shape[0]\n",
    "n_0   = np.where(hits==0)[0].shape[0]\n",
    "n_1   = np.where(hits==1)[0].shape[0]\n",
    "accuracy = (float(n_tot-n_0) / float(n_tot)) * 100\n",
    "print('Accuracy = {:d}/{:d} ({:.2f} %)'.format(n_1, n_tot, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
